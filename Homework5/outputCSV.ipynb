{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification,\\\n",
    "    TrainingArguments, Trainer, pipeline, DataCollatorWithPadding, set_seed\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset snli (C:/Users/zebzi/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab59af8eb7a4bdcaaaa0fe0681e4b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get the dataset\n",
    "snli = load_dataset(\"snli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--train_text[0]--: A person on a horse jumps over a broken down airplane. A person is training his horse for a competition.\n",
      "--original + hypothesis--: A person on a horse jumps over a broken down airplane.A person is training his horse for a competition.\n",
      "\n",
      "--test_text[0]--: This church choir sings to the masses as they sing joyous songs from the book at a church. The church has cracks in the ceiling.\n",
      "--original + hypothesis--: This church choir sings to the masses as they sing joyous songs from the book at a church.The church has cracks in the ceiling.\n",
      "\n",
      "--valid_text[0]--: Two women are embracing while holding to go packages. The sisters are hugging goodbye while holding to go packages after just eating lunch.\n",
      "--original + hypothesis--: Two women are embracing while holding to go packages.The sisters are hugging goodbye while holding to go packages after just eating lunch.\n"
     ]
    }
   ],
   "source": [
    "# per chatGPT's suggestion, let's concatenate premise + hypothesis into a \"text\" column.\n",
    "train_text = np.char.add(np.char.add(snli['train']['premise'], ' '), snli['train']['hypothesis'])\n",
    "test_text = np.char.add(np.char.add(snli['test']['premise'], ' '), snli['test']['hypothesis'])\n",
    "valid_text = np.char.add(np.char.add(snli['validation']['premise'], ' '), snli['validation']['hypothesis'])\n",
    "\n",
    "# let's do a sanity check to make sure concatenation was done correctly\n",
    "print(f'--train_text[0]--: {train_text[0]}')\n",
    "print(f'--original + hypothesis--: {snli[\"train\"][\"premise\"][0]+snli[\"train\"][\"hypothesis\"][0]}\\n')\n",
    "\n",
    "print(f'--test_text[0]--: {test_text[0]}')\n",
    "print(f'--original + hypothesis--: {snli[\"test\"][\"premise\"][0]+snli[\"test\"][\"hypothesis\"][0]}\\n')\n",
    "\n",
    "print(f'--valid_text[0]--: {valid_text[0]}')\n",
    "print(f'--original + hypothesis--: {snli[\"validation\"][\"premise\"][0]+snli[\"validation\"][\"hypothesis\"][0]}')\n",
    "\n",
    "snli[\"train\"] = snli[\"train\"].remove_columns([\"premise\", \"hypothesis\"])\n",
    "snli[\"train\"] = snli[\"train\"].add_column(\"text\", train_text)\n",
    "\n",
    "snli[\"test\"] = snli[\"test\"].remove_columns([\"premise\", \"hypothesis\"])\n",
    "snli[\"test\"] = snli[\"test\"].add_column(\"text\", test_text)\n",
    "\n",
    "snli[\"validation\"] = snli[\"validation\"].remove_columns([\"premise\", \"hypothesis\"])\n",
    "snli[\"validation\"] = snli[\"validation\"].add_column(\"text\", valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\zebzi\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-a7e3f6a12dd5470b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\zebzi\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-10263cd2a97d376b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\zebzi\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-7dd2e0b9c4e30d43.arrow\n",
      "Loading cached processed dataset at C:\\Users\\zebzi\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-6a07a2c8d2f1ad8c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\zebzi\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-aa9d2d1182cd7304.arrow\n",
      "Loading cached processed dataset at C:\\Users\\zebzi\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-f24845af267d924d.arrow\n"
     ]
    }
   ],
   "source": [
    "snli = snli.filter(lambda example: example[\"label\"] != -1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# tokenizer.to('cuda')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "    \n",
    "tokenized_snli= snli.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model that was trained in HW1\n",
    "id2label = {0: \"entailment\", 1: \"neutral\", 2:\"contradiction\"}\n",
    "label2id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"config.json\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"pytorch_model.bin\", config=config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Premise: A Ford car is making a right turn as 3 males are walking across the street behind the car\n",
      "Hypothesis:  A sedan was turning a corner as walkers were crossing\n",
      "Confidence: 0.027\n",
      "The prediction is:  entailment\n",
      "The correct is:  neutral\n",
      "\n",
      "Premise: Three boys in white shirts are walking behind an older model Ford car\n",
      "Hypothesis:  The boys are on the street\n",
      "Confidence: 0.159\n",
      "The prediction is:  neutral\n",
      "The correct is:  entailment\n",
      "\n",
      "Premise: Three girls blow out the candles of a cake made of Peeps\n",
      "Hypothesis:  There are peeps in the garden\n",
      "Confidence: 0.261\n",
      "The prediction is:  neutral\n",
      "The correct is:  contradiction\n",
      "\n",
      "Premise: A crowd of people looking up at 3 people on the edge of the roof of a building\n",
      "Hypothesis:  The crowd on the ground is watching 3 people on the roof's edge\n",
      "Confidence: 0.042\n",
      "The prediction is:  neutral\n",
      "The correct is:  entailment\n",
      "\n",
      "Premise: A person with a purple shirt is painting an image of a woman on a white wall\n",
      "Hypothesis:  A woman paints a portrait of a person\n",
      "Confidence: 0.001\n",
      "The prediction is:  contradiction\n",
      "The correct is:  neutral\n",
      "\n",
      "Premise: The flight attendant dressed in yellow demonstrates life vest usage\n",
      "Hypothesis:  A woman is preparing drinks on an airplane\n",
      "Confidence: 0.223\n",
      "The prediction is:  neutral\n",
      "The correct is:  contradiction\n",
      "\n",
      "Premise: The girls walk down the street\n",
      "Hypothesis:  Girls set down in the street\n",
      "Confidence: 0.395\n",
      "The prediction is:  entailment\n",
      "The correct is:  contradiction\n",
      "\n",
      "Premise: A man of the cloth puts a black substance on a man's forehead\n",
      "Hypothesis:  The men are at church\n",
      "Confidence: 0.066\n",
      "The prediction is:  contradiction\n",
      "The correct is:  neutral\n",
      "\n",
      "Premise: a boy holding onto the wall of an old brick house's raised foundation\n",
      "Hypothesis:  a boy is against the wall of a raised foundation\n",
      "Confidence: 0.341\n",
      "The prediction is:  neutral\n",
      "The correct is:  entailment\n",
      "\n",
      "Premise: This child is on the library steps\n",
      "Hypothesis:  The child is on the steps inside the library\n",
      "Confidence: 0.092\n",
      "The prediction is:  entailment\n",
      "The correct is:  neutral\n",
      "\n",
      "Premise: a boy in a red hooded top is smiling whilst looking away from his reflection\n",
      "Hypothesis:  The boy doesn't want to see his reflection\n",
      "Confidence: 0.400\n",
      "The prediction is:  entailment\n",
      "The correct is:  neutral\n",
      "\n",
      "Premise: Several younger people sitting in front of a statue\n",
      "Hypothesis:  several young people sitting outside\n",
      "Confidence: 0.100\n",
      "The prediction is:  entailment\n",
      "The correct is:  neutral\n",
      "\n",
      "Premise: A man, woman, and child get their picture taken in front of the mountains\n",
      "Hypothesis:  A family on vacation is posing\n",
      "Confidence: 0.005\n",
      "The prediction is:  neutral\n",
      "The correct is:  entailment\n",
      "\n",
      "Premise: A guy wearing jeans and a hat is crouching on a handrail with a concrete embankment located in front of him\n",
      "Hypothesis:  He is wearing a button-up shirt\n",
      "Confidence: 0.498\n",
      "The prediction is:  contradiction\n",
      "The correct is:  neutral\n",
      "\n",
      "Premise: A group of people gathered at night watching an event\n",
      "Hypothesis:  A group of humans are looking at the same direction\n",
      "Confidence: 0.001\n",
      "The prediction is:  entailment\n",
      "The correct is:  neutral\n"
     ]
    }
   ],
   "source": [
    "# Load the pipeline for natural language inference tasks\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device)\n",
    "# tokenized_snli[\"test\"][\"text\"][0]\n",
    "count = 0\n",
    "i = 0\n",
    "\n",
    "rowsList = []\n",
    "while(count < 50):\n",
    "    try:\n",
    "        temp = snli[\"test\"][\"text\"][i+100].split(\".\")\n",
    "        # print(tokenized_snli[\"test\"][\"text\"][i + 100])\n",
    "        premise = temp[0]\n",
    "        hypothesis = temp[1]\n",
    "    except:\n",
    "        print(\"no period\\n\")\n",
    "\n",
    "    outputs = tokenizer(snli[\"test\"][\"text\"][i+100], return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = outputs.to('cuda:0')\n",
    "    result = nlp.model(**outputs, output_hidden_states=True)\n",
    "    # result = nlp(tokenized_snli[\"test\"][\"text\"][i + 100])[0]'ArithmeticError\n",
    "\n",
    "    # print(result[\"logits\"].item())\n",
    "    predicted_token_class_ids = result.logits.argmax(-1)\n",
    "    predicted_label = nlp.model.config.id2label[predicted_token_class_ids.item()]\n",
    "    # dumb = result.logits.detach().cpu()\n",
    "    # dumb = np.array((result.logits[0][0].item(), result.logits[0][1].item(), result.logits[0][2].item()))\n",
    "    probability = np.exp(result.logits[0].detach().cpu().numpy()) / np.sum(np.exp(result.logits[0].detach().cpu().numpy()))\n",
    "    # probability = np.exp(dumb) / np.exp(np.sum(dumb))\n",
    "    # print(probability)\n",
    "\n",
    "    # print(result[\"hidden_states\"][12].shape)\n",
    "    temp = []\n",
    "    # print(f\"predicted_label: {predicted_label} and actual label: {id2label[tokenized_snli['test']['label'][i+100]]} with confidence: {probability[tokenized_snli['test']['label'][i+100]]:.3f}\")\n",
    "    if(predicted_label != id2label[tokenized_snli[\"test\"][\"label\"][i+100]]):\n",
    "        count += 1\n",
    "        print()\n",
    "        print(\"Premise: \",end=\"\")\n",
    "        print(premise)\n",
    "        print(\"Hypothesis: \",end=\"\")\n",
    "        print(hypothesis)\n",
    "        print(f\"Confidence: {1 - probability[tokenized_snli['test']['label'][i+100]]:.3f}\")\n",
    "        print(\"The prediction is: \", predicted_label)\n",
    "        print(\"The correct is: \", id2label[tokenized_snli[\"test\"][\"label\"][i+100]])\n",
    "        # temp = [str(count), f\"Premise: {premise} \\nHypothesis: {hypothesis}\", id2label[tokenized_snli[\"test\"][\"label\"][i+100]], f\"Confidence: {result['score']:.3f} \\n\" + result['label'], str(len(premise) + len(hypothesis))]\n",
    "        # rowsList.append(temp)\n",
    "    i += 1\n",
    "\n",
    "# with open(\"hw5CSV.csv\", mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow([\"\", \"Input Text\", \"Ground-Truth Label\", \"Predicted Label\", \"Input Text Length\"])\n",
    "#     writer.writerows(rowsList)\n",
    "# print(\"Here is i: \", i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
